{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv()\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c226cb19-e83a-4003-b64a-8034c36d3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a python expert programmer teaching secondary school students programming. Your\n",
    "task is to explain python code in an ELI5 manner such that technical concepts can be\n",
    "broken down into layman concepts for secondary school students, yet retain the technical\n",
    "jargon needed as this is a technical explanation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65a9f944-32a0-4216-994e-922567183c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Let's break down the code step by step in a way that’s easy to understand.\n",
       "\n",
       "### What does this code do?\n",
       "\n",
       "1. **The Set Comprehension**: \n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}` is a special way to create a set (which is like a box that holds unique items).\n",
       "   - You start with `books`, which is likely a list (or collection) of book objects.\n",
       "   - For each `book` in that list of `books`, you try to get the `author` using `book.get(\"author\")`.\n",
       "   - But there’s a condition: `if book.get(\"author\")`. This means you only include the author's name if it exists and isn't empty.\n",
       "\n",
       "2. **The `yield from` Statement**:\n",
       "   - `yield from` is a special keyword in Python used in generators. Think of a generator like a factory that produces items one at a time, instead of all at once.\n",
       "   - When you say `yield from`, you're telling Python to \"give out\" all the results from what comes after it (in this case, the set you've just created) to whoever is using this generator.\n",
       "\n",
       "### Why do we use this code?\n",
       "\n",
       "- **Unique Authors**: By using a set (with the `{}` braces), you're ensuring that each author is listed only once. If two books were written by the same author, that author will only show up one time in the results.\n",
       "  \n",
       "- **Cleaner Code**: Instead of writing a long loop to find authors, this code does it compactly and clearly using the power of comprehensions.\n",
       "\n",
       "- **Lazy Evaluation**: Thanks to the `yield from`, this generator doesn’t compute all the authors right away. It only gets each author when you ask for it. This saves memory and can be efficient for large collections of books.\n",
       "\n",
       "### In summary:\n",
       "\n",
       "This code is a neat and efficient way to gather all unique authors from a list of books and provide them one by one (thanks to `yield from`). It helps keep the program clean and makes sure we don’t list any author more than once!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "stream = openai.chat.completions.create(model=MODEL_GPT, messages=messages,stream=True)\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down this line of code into simpler terms that anyone can understand.\n",
      "\n",
      "**Imagine you have a bunch of books, each with its own author.**\n",
      "\n",
      "In Python, we use something called \"lists\" to store these books. Think of it like a list of all the authors in these books.\n",
      "\n",
      "The `yield from` part is a fancy way of saying \"give me all the items from this list\".\n",
      "\n",
      "**So, what does this line of code do?**\n",
      "\n",
      "It takes the list of all the books and extracts only the authors' names that are present in these books.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "- The `{book.get(\"author\") for book in books if book.get(\"author\")}` part is like a filter. It checks each book to see if it has an author (by looking at the `\"author\"` key).\n",
      "  - If a book has an author, its name is added to the list.\n",
      "  - But, if a book doesn't have an author, we skip that book.\n",
      "\n",
      "- The `yield from` part then takes this filtered list of authors and gives us each of them one by one. It's like taking turns giving us each author's name, one at a time.\n",
      "\n",
      "So, in essence, it extracts all the unique authors' names from these books and gives them to us one by one.\n",
      "\n",
      "**Why do we use `yield from` instead of just using a for loop?**\n",
      "\n",
      "Using `yield from` is faster because it doesn't store the entire list of authors in memory. Instead, it generates each author's name on-the-fly as we need them. This can be useful when working with large datasets where storing all the data at once would be too much.\n",
      "\n",
      "Think of it like having a super-long line of books where you just want to read one book at a time. Instead of reading the entire long list, `yield from` lets us pick up each book's author one by one!\n"
     ]
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7cb4b-6f40-40f6-a7fe-14bb8ce0f070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
